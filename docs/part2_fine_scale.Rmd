---
title: 'Part2: Landscape utilization modeling at fine scale'
author: "Lei Song"
date: "7/17/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(sf)
library(here)
library(raster)
library(terra)
library(ggplot2)
library(purrr)
library(pbmcapply)
library(dplyr)

data_path <- here("data")
rst_path <- file.path(data_path, "rasters")
vct_path <- file.path(data_path, "vectors")
pat_path <- file.path(data_path, "vars_patch")
result_path <- here("results")
walk(c(rst_path, vct_path, pat_path, result_path), function(pth) {
    if (!dir.exists(pth)) dir.create(pth)
})
```

## Introduction

From part one, we get the prior knowledge of landscape priority at coarse scales. This part will focus on modeling landscape utilization at fine scale (1km). Thus, the variables used will be slightly different from part 1. In part 1, large-scale summarized variables are mainly be used, such as landscape metrics, climatic condition, long-term food resource, and density-based features. According to the multi-scale analysis in part1, we know that landscape-level landscape metrics have more impact on elephant distribution at large scale, and class-level landscape metrics have more impact at fine scale. So in part2, we should focus on class-level metrics.

In this part, the used features are:

- Some moving-window landscape metrics

  - Contiguity index distribution (Savanna)
  - Mean of patch area (Savanna)
  - Savanna patch density
  - Ratio of savanna/water

- NDVI (wet season) and seasonality (done)
- BIO4 (the most important climatic variable in part1) (done)
- Moving-window surface roughness (done)
- And distance-based features (done)

Based on the normal size of elephant herd and available datasets, we selected 1km as the resolution. The used moving windows are 3(3km), 5(km), 7(km) because they are scales between 1km and 10km. An optimal scale analysis will be applied for modeling.

## Occurrence of African savanna elephant

This data has been prepared in part1.

## Environmental variables
### Bioclimatic variables

```{r}
library(itsdm)
library(stars)
cli_path <- file.path(data_path, "worldclim")

sf_use_s2(FALSE)
bry <- read_sf(file.path(data_path, "vectors/mainland_tanzania.geojson"))
bry <- st_buffer(bry, 0.5)

scale <- 0.5
bios <- worldclim2(var = "bio", res = scale,
                   bry = bry, path = tempdir())awa
write_stars(bios, file.path(cli_path, sprintf("bios_%s.tif", scale)))
```

### Landcover

We did not simply resample land cover map for the main land cover type in 1km. Instead, we used a area preserving method to upscale the map.

```{r}
# devtools::install_github("LLeiSong/APUpscale")
library(APUpscale)

# Read datasets
lc <- rast(file.path(data_path, "landcover/landcover.tif"))
lc_coarse <- upscale(lc, cellsize = 1000)
writeRaster(lc_coarse, file.path(data_path, "landcover/landcover_1km.tif"))
```

### Landscape metrics

```{r}
source(file.path(here("scripts"), "landscape_metrics.R"))

bufs <- c(3, 5, 7)
walk(bufs, function(buf) {
    landscape_c_metrics_mv(buf, data_path)
})
```

### BIO4

```{r}
bio4 <- rast(file.path(cli_path, "bios_0.5.tif")) %>% subset(4)
writeRaster(bio4, file.path(pat_path, "bio4.tif"))
```

### NDVI (wet season) and seasonality

```{r}
# Wet season
ndvi_wet <- rast(file.path(data_path, 
                           "NDVI/lansat8_sr_13_19_wet_NDVI_mean_100m.tif"))
for (i in 1:10) {
   ndvi_wet <- focal(ndvi_wet, fun = mean, na.rm = TRUE, na.policy = "only") 
}

# Mean annual SD
ndvi_sd <- rast(file.path(data_path, 
                           "NDVI/lansat8_sr_13_19_NDVI_mean_sd_100m.tif"))
for (i in 1:10) {
    ndvi_sd <- focal(ndvi_sd, fun = mean, na.rm = TRUE, na.policy = "only")
}

ndvis <- c(ndvi_wet, ndvi_sd)
names(ndvis) <- c("ndvi_wet_season", "ndvi_seasonality")
template <- rast(file.path(pat_path, "bio4.tif"))
ndvis <- resample(ndvis, template)
writeRaster(ndvis, file.path(pat_path, "ndvi.tif"))
```

### Zonal topographic features

Here, we used Terrain Ruggedness Index (TRI) and vector roughness and they are calculated in GRASS GIS.

```{r}
library(rgrass7)

# First resample DSM map
template <- rast(file.path(pat_path, "bio4.tif"))
dsm <- rast(file.path(rst_path, "dsm_tanzania.tif"))
dsm <- resample(dsm, template, method = "bilinear")
writeRaster(dsm, file.path(rst_path, "dsm_tanzania_1km.tif"))

# Distances
## Use GRASS GIS for speed
## set up
gisBase <- '/Applications/GRASS-8.2.app/Contents/Resources'
crs_mer <- crs(rast(file.path(rst_path, "dsm_tanzania_1km.tif")), 
               proj = T)
initGRASS(gisBase = gisBase,
          home = tempdir(),
          gisDbase = tempdir(),  
          mapset = 'PERMANENT', 
          location = 'osm', 
          override = TRUE)
execGRASS("g.proj", flags = "c", 
          proj4 = crs_mer)
execGRASS('r.in.gdal', flags = c("o", "overwrite"),
          input = file.path(rst_path, "dsm_tanzania_1km.tif"),
          band = 1,
          output = "elevation")
execGRASS("g.region", raster = "elevation")

# calculate vector roughness
# execGRASS("g.extension", extension = "r.vector.ruggedness")
execGRASS('r.vector.ruggedness', flags = c("overwrite"),
          elevation = "elevation",
          size = c(3, 5, 7),
          output = "vrm")

# save out
execGRASS('i.group',
          group = "vrms",
          input = c("vrm_3", "vrm_5", "vrm_7"))
execGRASS('r.out.gdal', flags = c("m", "overwrite"),
          output = file.path(pat_path, "vrms.tif"),
          input = "vrms")
```

### Distances

```{r}
library(rgrass7)

# Distances
## Use GRASS GIS for speed
## set up
gisBase <- '/Applications/GRASS-8.2.app/Contents/Resources'
crs_mer <- crs(template, proj = T)
initGRASS(gisBase = gisBase,
          home = tempdir(),
          gisDbase = tempdir(),  
          mapset = 'PERMANENT', 
          location = 'osm', 
          override = TRUE)
execGRASS("g.proj", flags = "c", 
          proj4 = crs_mer)
execGRASS('r.in.gdal', flags = c("o", "overwrite"),
          input = file.path(pat_path, "bio4.tif"),
          band = 1,
          output = "template")
execGRASS("g.region", raster = "template")

# Big roads
big_roads <- read_sf(file.path(vct_path, "big_roads.geojson"))
writeVECT(big_roads, 'big_roads', v.in.ogr_flags = 'overwrite')
rm(big_roads)
execGRASS('v.to.rast', flags = c("overwrite"),
          parameters = list(input = 'big_roads', 
                            output = 'big_roads',
                            use = 'val',
                            value = 1))
execGRASS('r.grow.distance', flags = c("overwrite"),
          parameters = list(input = 'big_roads', 
                            distance = 'big_roads'))
execGRASS('r.out.gdal', flags = c("m", "overwrite"),
          output = file.path(pat_path, "dist_to_big_roads_1km.tif"),
          input = "big_roads")

# Waterbodies
waterbodies <- read_sf(file.path(vct_path, "waterbodies.geojson"))
writeVECT(waterbodies, 'waterbodies', v.in.ogr_flags = 'overwrite')
rm(waterbodies)
execGRASS('v.to.rast', flags = c("overwrite"),
          parameters = list(input = 'waterbodies', 
                            output = 'waterbodies',
                            use = 'val',
                            value = 1))
execGRASS('r.grow.distance', flags = c("overwrite"),
          parameters = list(input = 'waterbodies', 
                            distance = 'waterbodies'))
execGRASS('r.out.gdal', flags = c("m", "overwrite"),
          output = file.path(pat_path, "dist_to_waterbodies_1km.tif"),
          input = "waterbodies")

# Rivers
rivers <- read_sf(file.path(vct_path, "rivers.geojson"))
writeVECT(rivers, 'rivers', v.in.ogr_flags = 'overwrite')
rm(rivers)
execGRASS('v.to.rast', flags = c("overwrite"),
          parameters = list(input = 'rivers', 
                            output = 'rivers',
                            use = 'val',
                            value = 1))
execGRASS('r.grow.distance', flags = c("overwrite"),
          parameters = list(input = 'rivers', 
                            distance = 'rivers'))
execGRASS('r.out.gdal', flags = c("m", "overwrite"),
          output = file.path(pat_path, "dist_to_rivers_1km.tif"),
          input = "rivers")

# Settlement
settlement <- read_sf(file.path(vct_path, "buildings.geojson"))
writeVECT(settlement, 'settlement', v.in.ogr_flags = 'overwrite')
rm(settlement)
execGRASS('v.to.rast', flags = c("overwrite"),
          parameters = list(input = 'settlement', 
                            output = 'settlement',
                            use = 'val',
                            value = 1))
execGRASS('r.grow.distance', flags = c("overwrite"),
          parameters = list(input = 'settlement', 
                            distance = 'settlement'))
execGRASS('r.out.gdal', flags = c("m", "overwrite"),
          output = file.path(pat_path, "dist_to_settlements_1km.tif"),
          input = "settlement")

# Stack them and resample
dists_vct <- file.path(
    pat_path, sprintf("dist_to_%s_1km.tif", 
                      c("rivers", "settlements", "waterbodies", "big_roads")))
dists_vct <- do.call(c, lapply(dists_vct, rast))

# Cropland, do it separately because the projection is the same.
## set up
gisBase <- '/Applications/GRASS-8.2.app/Contents/Resources'
fname <- tempfile(fileext = ".tif")
lc <- rast(file.path(data_path, "landcover/landcover_1km.tif"))
lc <- project(lc, crs(rast(file.path(pat_path, "bio4.tif"))),
              method = "near")
lc <- resample(lc, rast(file.path(pat_path, "bio4.tif")), 
               method = "near", filename = fname)

crs_mer <- crs(rast(file.path(pat_path, "bio4.tif")), proj = T)
initGRASS(gisBase = gisBase,
          home = tempdir(),
          gisDbase = tempdir(),  
          mapset = 'PERMANENT', 
          location = 'osm', 
          override = TRUE)
execGRASS("g.proj", flags = "c", 
          proj4 = crs_mer)
execGRASS('r.in.gdal', flags = c("o", "overwrite"),
          input = fname,
          band = 1,
          output = "template")
execGRASS("g.region", raster = "template")

cropland <- lc
cropland[cropland != 1] <- NA
fname_temp <- tempfile(fileext = ".tif")
writeRaster(cropland, fname_temp)
execGRASS('r.in.gdal', flags = c("o", "overwrite"),
          input = fname_temp,
          band = 1,
          output = "cropland")
execGRASS('r.grow.distance', flags = c("overwrite"),
          parameters = list(input = 'cropland', 
                            distance = 'cropland'))
execGRASS('r.out.gdal', flags = c("m", "overwrite"),
          output = file.path(pat_path, "dist_to_crop_1km.tif"),
          input = "cropland")

tree <- lc
tree[tree != 2] <- NA
fname_temp <- tempfile(fileext = ".tif")
writeRaster(tree, fname_temp)
execGRASS('r.in.gdal', flags = c("o", "overwrite"),
          input = fname_temp,
          band = 1,
          output = "tree")
execGRASS('r.grow.distance', flags = c("overwrite"),
          parameters = list(input = 'tree', 
                            distance = 'tree'))
execGRASS('r.out.gdal', flags = c("m", "overwrite"),
          output = file.path(pat_path, "dist_to_tree_1km.tif"),
          input = "tree")

# Stack all dists together
dists <- file.path(
    pat_path, sprintf("dist_to_%s_1km.tif", 
                      c("tree", "crop")))
dists <- c(do.call(c, lapply(dists, rast)), dists_vct)

rm(dists_vct)
writeRaster(dists, file.path(pat_path, "dists_1km.tif"))
```

## Modeling
### Gather data

```{r}
source(file.path(here("scripts"), "gather_data.R"))

# boundary
bry <- read_sf(file.path(data_path, "vectors/mainland_tanzania.geojson"))
bry <- vect(bry[, 'FID'])
gather_data_fs(bry, pat_path)
```

### Variable analysis
#### Thin the occurrences

```{r}
occ <- read_sf(file.path(data_path, "observations/ele_occurrence.geojson"))

# Resample the occurrences
template <- raster(file.path(pat_path, "variables.tif"))
values(template) <- NA
occ <- rasterize(occ, template, fun = "count")
occ <- rasterToPoints(occ, spatial = TRUE) %>% 
        st_as_sf() %>% select()
```

#### Occurrence locations vs expert range map

```{r}
library(nngeo)
library(terra)
library(ggpubr)

# Read datasets
range_map <- read_sf(
    file.path(data_path, "observations/pseudo_blocks.geojson")) %>% 
    st_union() %>% st_remove_holes() %>% st_make_valid() %>% vect()
vars <- rast(file.path(pat_path, "variables.tif"))

# Extract values
vars_occ <- terra::extract(vars, occ) %>% select(-ID)
vars_range <- mask(crop(vars, range_map), range_map)
vars_range <- values(vars_range, dataframe = TRUE, na.rm = TRUE)

vars_nms <- data.frame(
    name = names(vars_range),
    full_name = c("BIO4", 
                  "NDVI (wet season)", "NDVI seasonality",
                  "Distance to trees", "Distance to farmlands",
                  "Distance to rivers", "Distance to settlements",
                  "Distance to waterbodies", 
                  "Distance to primary roads/railways",
                  "VRM (3km)", "VRM (5km)", "VRM (7km)",
                  "ED of Cropland (3km)", 
                  "AREA_MN of Savanna (3km)",
                  "CONTIG_MN of Savanna (3km)", 
                  "PD of Savanna (3km)",
                  "Ratio of cropland (3km)",
                  "Ratio of savanna (3km)",
                  "ED of Cropland (5km)", 
                  "AREA_MN of Savanna (5km)",
                  "CONTIG_MN of Savanna (5km)", 
                  "PD of Savanna (5km)",
                  "Ratio of cropland (5km)",
                  "Ratio of savanna (5km)",
                  "ED of Cropland (7km)", 
                  "AREA_MN of Savanna (7km)",
                  "CONTIG_MN of Savanna (7km)", 
                  "PD of Savanna (7km)",
                  "Ratio of cropland (7km)",
                  "Ratio of savanna (7km)"))
# Compare the value distribution of each variable
nms <- names(vars_range)[-c(4:9)]
index_log <- c(1:3, 9, 12, 15, 18, 21, 24)
fg_list <- lapply(1:length(nms), function(n){
    nm_var <- nms[n]
    values_occ <- vars_occ %>% select(all_of(nm_var)) %>% 
        mutate(type = "Occurrence") %>% rename(x = nm_var)
    values_range <- vars_range %>% select(all_of(nm_var)) %>% 
        mutate(type = "Expert Range Map") %>% rename(x = nm_var)
    values <- rbind(values_occ, values_range)
    
    # K-S distance
    ks_result <- ks.test(values_occ$x, values_range$x)
    
    # Remove outliers using bin = 30 the same as ggplot default value
    # Most of values come from expert range map, 
    # so use both dataset together, count < 50
    bins <- seq(min(values$x), max(values$x), 
                by = (max(values$x) - min(values$x)) / 30)
    nums <- table(cut(values$x, c(bins, Inf)))
    nums <- data.frame(bin = bins,
                       count = as.numeric(nums))
    # Usually the tails happen to the two direction of the values
    middle <- mean(values$x)
    min_tail <- nums %>% filter(bin < middle & count < 100)
    if (nrow(min_tail) > 0) {
        min_tail <- max(min_tail$bin)
    } else min_tail <- min(values$x)
    max_tail <- nums %>% filter(bin > middle & count < 100)
    if (nrow(max_tail) > 0) {
        max_tail <- min(max_tail$bin)
    } else max_tail <- max(values$x)
    values <- values %>% filter(x >= min_tail & x <= max_tail)
    
    if (n %in% index_log) {
        ggplot(values, aes(x = x, y = after_stat(ndensity))) + 
            geom_histogram(aes(fill = type), 
                           color = "white", alpha = 0.6,
                           position="identity") +
            geom_density(aes(fill = type, color = type),
                         alpha = 0.6) +
            scale_fill_brewer("Data type", palette = "Set1") +
            scale_color_brewer("Data type", palette = "Set1") +
            xlab(vars_nms %>% filter(name == nm_var) %>% pull(full_name)) + 
            ylab("Density") +
            annotate("text", x = min(values$x), y = 1, 
                      label = sprintf("K-S Distance: %s", 
                                      round(ks_result$statistic, 2)),
                     hjust = 0, vjust = 1, size = 3) +
            theme_classic() +
            theme(text = element_text(size = 9),
                  axis.title = element_text(size = 9),
                  axis.text = element_text(size = 9),
                  plot.margin = unit(c(0.2, 0.3, 0.1, 0.1), "cm"))
    } else {
        ggplot(values, aes(x = x, y = after_stat(ndensity))) + 
            geom_histogram(aes(fill = type), 
                           color = "white", alpha = 0.6,
                           position="identity") +
            geom_density(aes(fill = type, color = type),
                         alpha = 0.6) +
            scale_x_log10() +
            scale_fill_brewer("Data type", palette = "Set1") +
            scale_color_brewer("Data type", palette = "Set1") +
            xlab(vars_nms %>% filter(name == nm_var) %>% pull(full_name)) + 
            ylab("Density") +
            annotate("text", 
                     x = 0, y = 1, 
                     label = sprintf("K-S Distance: %s", 
                                     round(ks_result$statistic, 2)),
                     hjust = 0, size = 3) +
            theme_classic() +
            theme(text = element_text(size = 9),
                  axis.title = element_text(size = 9),
                  axis.text = element_text(size = 9),
                  plot.margin = unit(c(0.2, 0.3, 0.1, 0.1), "cm"))
    }
})

dist_fg_list <- lapply(names(vars_range)[c(4:9)], function(nm_var){
    values_occ <- vars_occ %>% select(all_of(nm_var)) %>% 
        mutate(type = "Occurrence") %>% rename(x = nm_var)
    values_range <- vars_range %>% select(all_of(nm_var)) %>% 
        mutate(type = "Expert Range Map") %>% rename(x = nm_var)
    values <- rbind(values_occ, values_range)
    
    # K-S distance
    ks_result <- ks.test(values_occ$x, values_range$x)
    
    # Remove outliers using bin = 30 the same as ggplot default value
    # Most of values come from expert range map, 
    # so use both dataset together, count < 50
    bins <- seq(min(values$x), max(values$x), 
                by = (max(values$x) - min(values$x)) / 30)
    nums <- table(cut(values$x, c(bins, Inf)))
    nums <- data.frame(bin = bins,
                       count = as.numeric(nums))
    # Usually the tails happen to the two direction of the values
    middle <- mean(values$x)
    min_tail <- nums %>% filter(bin < middle & count < 100)
    if (nrow(min_tail) > 0) {
        min_tail <- max(min_tail$bin)
    } else min_tail <- min(values$x)
    max_tail <- nums %>% filter(bin > middle & count < 100)
    if (nrow(max_tail) > 0) {
        max_tail <- min(max_tail$bin)
    } else max_tail <- max(values$x)
    values <- values %>% filter(x >= min_tail & x <= max_tail)
    
    ggplot(values, aes(x = x, y = after_stat(ndensity))) + 
        geom_histogram(aes(fill = type), 
                       color = "white", alpha = 0.6,
                       position="identity") +
        geom_density(aes(fill = type, color = type),
                     alpha = 0.6) +
        scale_x_log10() +
        scale_fill_brewer("Data type", palette = "Set1") +
        scale_color_brewer("Data type", palette = "Set1") +
        xlab(vars_nms %>% filter(name == nm_var) %>% pull(full_name)) + 
        ylab("Density") +
        annotate("text", 
                 x = 0, y = 1, 
                 label = sprintf("K-S Distance: %s", 
                                 round(ks_result$statistic, 2)),
                 hjust = 0, size = 3) +
        theme_classic() +
        theme(text = element_text(size = 9),
              axis.title = element_text(size = 9),
              axis.text = element_text(size = 10),
              plot.margin = unit(c(0.2, 0.3, 0.1, 0.1), "cm"))

})

# Reorganize the figures and plot them.
ggarrange(plotlist = fg_list[1:18], ncol = 3, nrow = 6, 
          common.legend = TRUE, legend = "bottom")

fg_path <- here("docs/figures")
ggsave(file.path(fg_path, "figureS1_vars_occ_range.png"), 
       width = 6.5, height = 8, dpi = 500, bg = "white")

ggarrange(plotlist = c(fg_list[19:24], dist_fg_list), 
          ncol = 3, nrow = 4, 
          common.legend = TRUE, legend = "bottom")

ggsave(file.path(fg_path, "figureS1_vars_occ_range_cnt.png"), 
       width = 6.5, height = 5.3, dpi = 500, bg = "white")

# Get the statistics
ks_statistics <- sapply(1:length(nms), function(n){
    nm_var <- nms[n]
    values_occ <- vars_occ %>% select(all_of(nm_var)) %>% 
        mutate(type = "Occurrence") %>% rename(x = nm_var)
    values_range <- vars_range %>% select(all_of(nm_var)) %>% 
        mutate(type = "Expert Range Map") %>% rename(x = nm_var)
    values <- rbind(values_occ, values_range)
    
    # K-S test
    ks_result <- ks.test(values_occ$x, values_range$x)
    round(ks_result$statistic, 2)
})
nms_to_move <- nms[ks_statistics >= 0.4]
nms_to_move <- c(nms_to_move, 
                 "dist_to_tree", "dist_to_rivers", "dist_to_big_roads")
```

#### Univariate model analysis

In this step, a bunch of univariate iForest models are built up using each continuous variable in the selected variables. Then the variables made by using different scales are compared and the optimal scale is selected for the final model.

```{r}
library(stringr)
library(stars)
library(pbmcapply)
source(here("scripts/modeling.R"))

# Read datasets
vars <- read_stars(file.path(pat_path, "variables.tif")) %>% 
    split("band")
vars_selected <- names(vars)[str_detect(names(vars), "_[0-9]{1}")]
vars <- vars %>% select(all_of(vars_selected))
occ <- read_sf(file.path(data_path, "observations/ele_occurrence.geojson"))
zone_to_thin <- read_sf(
    file.path(data_path, "observations/zone_to_thin.geojson"))

# Univariate modeling
univariate_test <- do.call(
    rbind, pbmclapply(names(vars), function(var_nm) {
    univariate_model(occ, vars %>% select(var_nm)) %>% 
        mutate(variable = var_nm)
}, mc.cores = 6))

save(univariate_test, file = file.path(result_path, "univariate_test.rda"))
```

##### Piece together the analysis

```{r}
# Get the best scales, use roc_ratio as the metrics
univariate_result <- univariate_test %>% 
    mutate(scale = str_extract(variable, "[0-9]{1}"),
           variable = str_replace(variable, "_[0-9]{1}", "")) %>%
    select(-fold) %>% 
    mutate(evaluation = auc_ratio + auc) %>% 
    group_by(variable, scale) %>% 
    summarise(across(everything(), mean)) %>% 
    select(variable, scale, evaluation, auc_ratio, auc)

nms <- data.frame(
    variable = c("cropland_ed", "cropland_ratio", 
                 "savanna_area_mn", "savanna_contig_mn",
                 "savanna_pd", "savanna_ratio", "vrm"),
    full_name = c("Cropland edge density", "Ratio of cropland",
                  "Mean of patch area (Savanna)", 
                  "Contiguity index distribution (Savanna)",
                  "Savanna patch density", "Ratio of savanna",
                  "Vector ruggedness measure"))

univariate_result <- univariate_result %>% 
    left_join(nms, by = "variable")

univariate_best <- univariate_result %>% 
    group_by(variable) %>% 
    summarise(evaluation = max(evaluation)) %>% 
    left_join(univariate_result, 
              by = c("variable", "evaluation"))

# Have a look
ggplot(univariate_best) +
    geom_point(aes(x = full_name, y = scale), color = "black", size = 3) +
    geom_text(aes(x = full_name, y = scale, 
                  label = sprintf("AUC[ratio]: %s", round(auc_ratio, 2))),
              check_overlap = TRUE, vjust = -5, parse = TRUE) +
    geom_text(aes(x = full_name, y = scale, 
                  label = sprintf("AUC: %s", round(auc, 2))),
              check_overlap = TRUE, vjust = -4) +
    xlab("Variable") + ylab("Scale (km)") +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust=0.5, hjust=1),
          axis.text = element_text(size = rel(1)),
          axis.title = element_text(size = rel(1)),
          text = element_text(size = 10))

ggsave(file.path(fg_path, "univariate_models.png"), 
       width = 8, height = 8, dpi = 500, bg = "white")
```

#### Subset the variables

```{r}
# Subset variable
vars <- rast(file.path(pat_path, "variables.tif"))
nms <- names(vars)
nms_keep_univariate_test <- c(nms[1:10], 
         c("vrm_3", "savanna_contig_mn_3", 
           "cropland_ed_7", "cropland_ratio_7",
           "savanna_ratio_7", "savanna_pd_7"))
nms_conflict <- intersect(nms_to_move, nms_keep_univariate_test)

# Both consider univariate test and variable distribution comparison,
# Remove savanna_ratio variable from the final model.
# Keep savanna_pd_3 instead of savanna_pd_7.
nms_to_keep <- c(setdiff(nms_keep_univariate_test, nms_conflict),
                 "savanna_pd_3")

vars_selected <- subset(vars, nms_to_keep)

writeRaster(vars_selected, 
            file.path(pat_path, "variables_repre_opt_scale.tif"))
```

So the selected variables with optimal scale and ROC higher than 0.5, and have similar distribution across occurrence coordinates and expert range map are:

**Topography:**

- Vector Ruggedness Measure (VRM) of 3 window size (3km) (`vrm_3`)

**Landscape condition:**

Class level:

- Contiguity index distribution (mean) (CONTIG_MN) of savanna (3 window size) (`savanna_contig_mn_3`)
- Edge density (ED) of cropland (7 window size) (`cropland_ed_7`)
- Ratio of cropland (7 window size) (`cropland_ratio_7`)
- Savanna patch density (3 window size) (`savanna_pd_3`)

#### Variable correlation analysis

```{r}
library(corrplot)
vars <- rast(file.path(pat_path, "variables_repre_opt_scale.tif"))
vars <- data.frame(vars) %>% na.omit()

corrplot(corr = cor(
    vars %>% select(-c(cropland_ratio_7, dist_to_crop)), 
    method = "spearman"),
    method = "square", type = "lower",
    diag = FALSE, addCoef.col = "black",
    number.cex = 0.7, tl.cex = 0.7)

# Subset the variables for final model
vars <- rast(file.path(pat_path, "variables_repre_opt_scale.tif"))
bands_select <- setdiff(
    names(vars), 
    c('dist_to_crop', 'cropland_ratio_7'))
vars <- subset(vars, bands_select)
writeRaster(vars, file.path(pat_path, "variables_final.tif"))
```

So after three tests, the final variables to use are:

**Bioclimatic variables:**

- BIO4 = Temperature Seasonality (standard deviation ×100)

**Vegetation:**

- NDVI Seasonality (standard deviation)

**Distance-based features:**

- Distance to settlements
- Distance to waterbodies

**Topography:**

- Vector Ruggedness Measure (VRM) (3km)

**Landscape condition:**

Class level:

- Contiguity index distribution (mean) (CONTIG_MN) of savanna (3km)
- Edge density (ED) of cropland (7km)
- Savanna patch density (3km)
- Ratio of Savanna (7km)

### Modeling with Isolation Forest (Bayes fusion later)

This method do modeling separately at these two scales, and use Bayes fusion method to fuse the two result. The prediction at coarse scale acts as the prior probability.

#### Hyper-parameter tuning

- sample_size = c(0.8, 0.85, 0.9, 0.95, 0.1)
- max_depth = seq(30, min(floor(num_sample / 2), 180), 30)
- ndim = c(2, 3, 4)
- scoring_metric = c("depth", "adj_depth")

```{r}
source(here("scripts/modeling.R"))
occ <- read_sf(file.path(data_path, "observations/ele_occurrence.geojson"))
zone_to_thin <- read_sf(
    file.path(data_path, "observations/zone_to_thin.geojson"))
param_tuning_fs(occ, pat_path, result_path, zone_to_thin = zone_to_thin)
```

#### Modeling

```{r}
source(here("scripts/modeling.R"))

# Load the best parameters
load(file.path(result_path, "tuning_cv_fs.rda"))
best_params <- tuning_cv %>% 
    arrange(desc(boyce_index), desc(auc_ratio), desc(auc), desc(tss)) %>%
    slice(1) %>% 
    select(sample_size, max_depth, ndim, scoring_metric)

# run models
occ <- read_sf(file.path(data_path, "observations/ele_occurrence.geojson"))
zone_to_thin <- read_sf(
    file.path(data_path, "observations/zone_to_thin.geojson"))
modeling_fs(best_params, occ, pat_path, 
            result_path, zone_to_thin = zone_to_thin)
```

#### Integrate two maps

```{r}
# Prediction at 1km scale made by 10km scale model
pred_5_to_1 <- read_stars(
    file.path(result_path, "landscape_utility_10km_to_1km.tif")) %>% 
    split("band") %>% select("prediction")

# Prediction at 1km scale
load(file.path(result_path, "runs_fs.rda"))
predictions <- lapply(runs, function(run) {
    prediction <- run$prediction
    st_dimensions(prediction) <- st_dimensions(pred_5_to_1)
    
    # Integrated map
    pred_integrated <- prediction * pred_5_to_1 / 
        (prediction * pred_5_to_1 + (1 - prediction) * (1 - pred_5_to_1))
    
    # Evaluate the map
    mod <- run$model
    occ_pred <- st_extract(pred_integrated, run$pts_occ) %>% pull(prediction)
    bg_pred <- st_extract(pred_integrated, run$pts_bg_occ) %>% pull(prediction)
    var_pred <- na.omit(as.vector(run$prediction[[1]]))
    
    eval_integrated <- evaluate_po(
        mod, occ_pred = occ_pred, 
        bg_pred = bg_pred, var_pred = var_pred)
    
    list('prediction' = pred_integrated,
         'evaluation' = eval_integrated)
})

pred_1km <- merge(
    do.call(c, lapply(runs, function(run) run$prediction))) %>% 
    st_apply(c("x", "y"), mean, na.rm = TRUE)

pred_1km_sd <- merge(
    do.call(c, lapply(runs, function(run) run$prediction))) %>% 
    st_apply(c("x", "y"), sd, na.rm = TRUE)

pred_1km <- c(pred_1km, pred_1km_sd)
names(pred_1km) <- c("prediction", "standard deviation")

fname <- file.path(result_path, "landscape_utility_1km.tif")
write_stars(merge(pred_1km), fname)

pred_integrated <- merge(
    do.call(c, lapply(predictions, function(pred) pred$prediction))) %>% 
    st_apply(c("x", "y"), mean, na.rm = TRUE)

pred_integrated_sd <- merge(
    do.call(c, lapply(predictions, function(pred) pred$prediction))) %>% 
    st_apply(c("x", "y"), sd, na.rm = TRUE)
pred_integrated <- c(pred_integrated, pred_integrated_sd)
names(pred_integrated) <- c("prediction", "standard deviation")

fname <- file.path(result_path, "landscape_utility_1km_integrated.tif")
write_stars(merge(pred_integrated), fname)

eval_fine_integrated <- lapply(predictions, function(pred) pred$evaluation)
save(eval_fine_integrated, 
     file = file.path(result_path, "eval_fine_integrated.rda"))
```
